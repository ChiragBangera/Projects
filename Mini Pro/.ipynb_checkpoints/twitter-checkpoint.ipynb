{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "641f2d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "import pandas as pd\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9055b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display data of each tweet\n",
    "def printtweetdata(n, ith_tweet):\n",
    "    print()\n",
    "    print(f\"Tweet {n}:\")\n",
    "    print(f\"Username:{ith_tweet[0]}\")\n",
    "    print(f\"Description:{ith_tweet[1]}\")\n",
    "    print(f\"Location:{ith_tweet[2]}\")\n",
    "    print(f\"Following Count:{ith_tweet[3]}\")\n",
    "    print(f\"Follower Count:{ith_tweet[4]}\")\n",
    "    print(f\"Total Tweets:{ith_tweet[5]}\")\n",
    "    print(f\"Retweet Count:{ith_tweet[6]}\")\n",
    "    print(f\"Tweet Text:{ith_tweet[7]}\")\n",
    "    print(f\"Hashtags Used:{ith_tweet[8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03aa6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform data extraction\n",
    "def scrape(words, date_since, numtweet):\n",
    "      \n",
    "    # Creating DataFrame using pandas\n",
    "    db = pd.DataFrame(columns=['username', 'description', 'location', 'following',\n",
    "                               'followers', 'totaltweets', 'retweetcount', 'text', 'hashtags'])\n",
    "      \n",
    "    # We are using .Cursor() to search through twitter for the required tweets.\n",
    "    # The number of tweets can be restricted using .items(number of tweets)\n",
    "    tweets = tweepy.Cursor(api.search, q=words, lang=\"en\",\n",
    "                           since=date_since, tweet_mode='extended').items(numtweet)\n",
    "     \n",
    "    # .Cursor() returns an iterable object. Each item in \n",
    "    # the iterator has various attributes that you can access to \n",
    "    # get information about each tweet\n",
    "    list_tweets = [tweet for tweet in tweets]\n",
    "      \n",
    "    # Counter to maintain Tweet Count\n",
    "    i = 1  \n",
    "      \n",
    "    # we will iterate over each tweet in the list for extracting information about each tweet\n",
    "    for tweet in list_tweets:\n",
    "        username = tweet.user.screen_name\n",
    "        description = tweet.user.description\n",
    "        location = tweet.user.location\n",
    "        following = tweet.user.friends_count\n",
    "        followers = tweet.user.followers_count\n",
    "        totaltweets = tweet.user.statuses_count\n",
    "        retweetcount = tweet.retweet_count\n",
    "        hashtags = tweet.entities['hashtags']\n",
    "          \n",
    "        # Retweets can be distinguished by a retweeted_status attribute,\n",
    "        # in case it is an invalid reference, except block will be executed\n",
    "        try:\n",
    "            text = tweet.retweeted_status.full_text\n",
    "        except AttributeError:\n",
    "            text = tweet.full_text\n",
    "        hashtext = list()\n",
    "        for j in range(0, len(hashtags)):\n",
    "            hashtext.append(hashtags[j]['text'])\n",
    "          \n",
    "        # Here we are appending all the extracted information in the DataFrame\n",
    "        ith_tweet = [username, description, location, following,\n",
    "                     followers, totaltweets, retweetcount, text, hashtext]\n",
    "        db.loc[len(db)] = ith_tweet\n",
    "          \n",
    "        # Function call to print tweet data on screen\n",
    "        printtweetdata(i, ith_tweet)\n",
    "        i = i+1\n",
    "    filename = 'scraped_tweets.csv'\n",
    "      \n",
    "    # we will save our database as a CSV file.\n",
    "    db.to_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b2d66ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Twitter HashTag to search for\n",
      "#diwali\n",
      "Enter Date since The Tweets are required in yyyy-mm--dd\n",
      "2021-11-1\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'API' object has no attribute 'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10172/2558829440.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m# number of tweets you want to extract in one run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mnumtweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_since\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumtweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Scraping has completed!'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10172/3243429803.py\u001b[0m in \u001b[0;36mscrape\u001b[1;34m(words, date_since, numtweet)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# We are using .Cursor() to search through twitter for the required tweets.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;31m# The number of tweets can be restricted using .items(number of tweets)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     tweets = tweepy.Cursor(api.search, q=words, lang=\"en\",\n\u001b[0m\u001b[0;32m     11\u001b[0m                            since=date_since, tweet_mode='extended').items(numtweet)\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'API' object has no attribute 'search'"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "      \n",
    "    # Enter your own credentials obtained \n",
    "    # from your developer account\n",
    "    consumer_key = \"XXXXXXXXXXXXXXXXXXXXX\"\n",
    "    consumer_secret = \"XXXXXXXXXXXXXXXXXXXXX\"\n",
    "    access_key = \"XXXXXXXXXXXXXXXXXXXXX\"\n",
    "    access_secret = \"XXXXXXXXXXXXXXXXXXXXX\"\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_key, access_secret)\n",
    "    api = tweepy.API(auth)\n",
    "      \n",
    "    # Enter Hashtag and initial date\n",
    "    print(\"Enter Twitter HashTag to search for\")\n",
    "    words = input()\n",
    "    print(\"Enter Date since The Tweets are required in yyyy-mm--dd\")\n",
    "    date_since = input()\n",
    "      \n",
    "    # number of tweets you want to extract in one run\n",
    "    numtweet = 100  \n",
    "    scrape(words, date_since, numtweet)\n",
    "    print('Scraping has completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915c06bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
